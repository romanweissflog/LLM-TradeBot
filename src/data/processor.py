"""
å¸‚åœºæ•°æ®å¤„ç†æ¨¡å—
"""
import pandas as pd
import numpy as np
import uuid
from typing import Dict, List, Optional, Tuple
from datetime import datetime
from ta.trend import SMAIndicator, EMAIndicator, MACD, ADXIndicator
from ta.momentum import RSIIndicator, StochasticOscillator
from ta.volatility import BollingerBands, AverageTrueRange
from ta.volume import VolumeWeightedAveragePrice
from src.utils.logger import log
from src.utils.data_saver import DataSaver
from src.data.kline_validator import KlineValidator

class MarketDataProcessor:
    """å¸‚åœºæ•°æ®å¤„ç†å™¨"""
    
    # æŒ‡æ ‡è®¡ç®—å‚æ•°ï¼ˆé€æ˜åŒ–ï¼‰
    INDICATOR_PARAMS = {
        'sma': [20, 50],
        'ema': [12, 26],
        'macd': {'fast': 12, 'slow': 26, 'signal': 9},
        'rsi': {'period': 14},
        'bollinger': {'period': 20, 'std_dev': 2},
        'atr': {'period': 14},
        'volume_sma': {'period': 20}
    }
    
    # å¤„ç†å™¨ç‰ˆæœ¬ï¼ˆç”¨äºå¿«ç…§è¿½è¸ªï¼‰
    PROCESSOR_VERSION = 'processor_v2'

    def __init__(self):
        self.df_cache: Dict[str, pd.DataFrame] = {}
        self.validator = KlineValidator()
        self.saver = DataSaver()  # âœ… åˆå§‹åŒ–æ•°æ®ä¿å­˜å™¨
        self.last_snapshot_id: Optional[str] = None
        self.last_snapshot_data: Optional[Dict] = None
    
    def process_klines(
        self, 
        klines: List[Dict], 
        symbol: str, 
        timeframe: str,
        validate: bool = True,
        save_raw: bool = True
    ) -> pd.DataFrame:
        """
        å¤„ç†Kçº¿æ•°æ®ï¼Œè®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        
        Args:
            klines: Kçº¿åŸå§‹æ•°æ®
            symbol: äº¤æ˜“å¯¹
            timeframe: æ—¶é—´å‘¨æœŸ
            validate: æ˜¯å¦è¿›è¡Œæ•°æ®éªŒè¯å’Œæ¸…æ´—
            
        Returns:
            åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„DataFrame
        """
        if not klines:
            log.warning(f"[{symbol}] Kçº¿æ•°æ®ä¸ºç©º: {timeframe}")
            return pd.DataFrame()
        
        # âœ… Save Step 1: åŸå§‹Kçº¿æ•°æ®
        if save_raw:
            self.saver.save_step1_klines(klines, symbol, timeframe)
        
        n_original = len(klines)
        
        # 1. æ•°æ®éªŒè¯å’Œæ¸…æ´—
        anomaly_details = None
        if validate:
            klines, validation_report = self.validator.validate_and_clean_klines(
                klines, 
                symbol,
                action='remove'
            )
            
            anomaly_details = {
                'removed_count': validation_report.get('removed_count', 0),
                'issues': validation_report.get('issues', []),
                'method': validation_report.get('method', 'Integrity-Check-Only')
            }
            
            if validation_report.get('removed_count', 0) > 0:
                log.warning(
                    f"[{symbol}] æ•°æ®éªŒè¯: åŸå§‹={n_original}, "
                    f"æ¸…æ´—å={len(klines)}, "
                    f"åˆ é™¤={validation_report['removed_count']}, "
                    f"æ–¹æ³•={validation_report['method']}"
                )
        
        # 2. æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
        required_bars = max(self.INDICATOR_PARAMS['sma'])  # 50
        if len(klines) < required_bars:
            # Enhanced debugging: log first few items to see what we got
            preview = klines[:3] if klines else "Empty"
            log.error(
                f"[{symbol}] Kçº¿æ•°é‡ä¸è¶³: éœ€è¦>={required_bars}, "
                f"å®é™…={len(klines)}, "
                f"Data Preview: {preview}"
            )
            return pd.DataFrame()
        
        log.debug(
            f"[{symbol}] å¤„ç†Kçº¿: timeframe={timeframe}, "
            f"bars={len(klines)}, params={self.INDICATOR_PARAMS}"
        )
        
        # 3. è½¬æ¢ä¸ºDataFrame
        df = pd.DataFrame(klines)
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        
        # 4. è®¡ç®—æŠ€æœ¯æŒ‡æ ‡
        df = self._calculate_indicators(df)
        
        # 5. æ·»åŠ æŒ‡æ ‡ warm-up æ ‡è®°
        df = self._mark_warmup_period(df)
        
        # 6. ç”Ÿæˆå¿«ç…§ID
        snapshot_id = str(uuid.uuid4())[:8]
        df['snapshot_id'] = snapshot_id
        
        # âœ… Save Step 2: æŠ€æœ¯æŒ‡æ ‡æ•°æ®
        self.saver.save_step2_indicators(df, symbol, timeframe, snapshot_id)
        
        # 7. ç¼“å­˜
        cache_key = f"{symbol}_{timeframe}"
        self.df_cache[cache_key] = df
        
        # 8. è®°å½•æœ€åå¿«ç…§ä¿¡æ¯
        self.last_snapshot_id = snapshot_id
        latest = df.iloc[-1]
        self.last_snapshot_data = {
            'snapshot_id': snapshot_id,
            'timestamp': latest.name,
            'symbol': symbol,
            'timeframe': timeframe,
            'close': float(latest['close']),
            'volume': float(latest['volume']),
            'n_bars_used': len(df),
            'min_valid_index': self._get_min_valid_index(),
            'anomaly_details': anomaly_details
        }
        
        log.debug(
            f"[{symbol}] å¿«ç…§ç”Ÿæˆ: id={snapshot_id}, "
            f"timestamp={latest.name}, price={latest['close']:.2f}"
        )
        
        return df

    def get_market_state(self, df: pd.DataFrame) -> Dict:
        """è·å–å¸‚åœºçŠ¶æ€æ‘˜è¦"""
        if df.empty:
            return {}
        
        latest = df.iloc[-1]
        
        # åŸºç¡€æŒ‡æ ‡
        state = {
            'timestamp': str(latest.name),
            'close': float(latest['close']),
            'price': float(latest['close']),
            'trend': self.detect_trend(df),
            'volatility': self.detect_volatility(df),
            'momentum': self.detect_momentum(df),
            'rsi': float(latest.get('rsi', 0)),
            'macd': float(latest.get('macd', 0)),
            'macd_signal': 'buy' if latest.get('macd', 0) > latest.get('macd_signal', 0) else 'sell',
            'volume_ratio': float(latest.get('volume_ratio', 1.0)),
            'volume_change_pct': 0.0,
            'atr_pct': float(latest.get('atr', 0)) / float(latest['close']) * 100 if latest['close'] != 0 else 0,
            'key_levels': self.find_support_resistance(df),
            'snapshot_id': latest.get('snapshot_id', 'unknown'),
            'indicator_completeness': self.check_indicator_completeness(df)
        }
        
        # Calculate volume change
        if len(df) >= 2:
            prev_vol = df['volume'].iloc[-2]
            curr_vol = df['volume'].iloc[-1]
            if prev_vol > 0:
                state['volume_change_pct'] = (curr_vol - prev_vol) / prev_vol * 100
        
        return state
    
    def _calculate_indicators(self, df: pd.DataFrame) -> pd.DataFrame:
        """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡"""
        
        # ç§»åŠ¨å¹³å‡çº¿
        df['sma_20'] = SMAIndicator(close=df['close'], window=20).sma_indicator()
        df['sma_50'] = SMAIndicator(close=df['close'], window=50).sma_indicator()
        # Fast EMAs for quick trend detection (used by risk manager)
        df['ema_5'] = EMAIndicator(close=df['close'], window=5).ema_indicator()
        df['ema_13'] = EMAIndicator(close=df['close'], window=13).ema_indicator()
        # Standard EMAs for MACD and other indicators
        df['ema_12'] = EMAIndicator(close=df['close'], window=12).ema_indicator()
        df['ema_26'] = EMAIndicator(close=df['close'], window=26).ema_indicator()
        
        # ğŸ†• Trend EMAs for 1h dual EMA system (Specification requirement)
        df['ema_20'] = EMAIndicator(close=df['close'], window=20).ema_indicator()
        df['ema_60'] = EMAIndicator(close=df['close'], window=60).ema_indicator()
        
        # MACD - ç»å…¸ä»·å·®å®šä¹‰ï¼ˆæ¢å¤æ ‡å‡†ï¼Œ2025-12-18ä¿®å¤ï¼‰
        # ä¿å­˜åŸå§‹MACDä»·å·®ï¼ˆå•ä½: USDTï¼‰ï¼Œç¬¦åˆç»å…¸æŠ€æœ¯åˆ†æå®šä¹‰
        # MACD = EMA12 - EMA26ï¼ˆä»·æ ¼å·®ï¼‰ï¼Œéç™¾åˆ†æ¯”
        # å‚è€ƒ: https://www.investopedia.com/terms/m/macd.asp
        macd_indicator = MACD(close=df['close'])
        df['macd'] = macd_indicator.macd()              # MACDçº¿ï¼ˆä»·å·®ï¼ŒUSDTï¼‰
        df['macd_signal'] = macd_indicator.macd_signal()  # ä¿¡å·çº¿ï¼ˆä»·å·®ï¼ŒUSDTï¼‰
        df['macd_diff'] = macd_indicator.macd_diff()     # æŸ±çŠ¶å›¾ï¼ˆä»·å·®ï¼ŒUSDTï¼‰
        
        # æ³¨æ„: å½’ä¸€åŒ–åº”åœ¨Step3ç‰¹å¾å·¥ç¨‹ä¸­è¿›è¡Œï¼Œè€ŒéStep2æŠ€æœ¯æŒ‡æ ‡è®¡ç®—
        # è‹¥éœ€è¦å½’ä¸€åŒ–ç‰ˆæœ¬ï¼Œè¯·åœ¨ç‰¹å¾å·¥ç¨‹éƒ¨åˆ†æ·»åŠ ï¼š
        #   df['macd_pct'] = (df['macd'] / df['close']) * 100
        
        # RSI
        df['rsi'] = RSIIndicator(close=df['close'], window=14).rsi()
        # ğŸ†• ADX Indicator (Added 2025-12-27)
        # ADX = Average Directional Index (Trend Strength)
        adx_indicator = ADXIndicator(high=df['high'], low=df['low'], close=df['close'], window=14)
        df['adx'] = adx_indicator.adx()
        
        # å¸ƒæ—å¸¦
        bb = BollingerBands(close=df['close'], window=20, window_dev=2)
        df['bb_upper'] = bb.bollinger_hband()
        df['bb_middle'] = bb.bollinger_mavg()
        df['bb_lower'] = bb.bollinger_lband()
        # å®‰å…¨è®¡ç®— bb_widthï¼Œé¿å…é™¤ä»¥0
        df['bb_width'] = np.where(
            df['bb_middle'] > 0,
            (df['bb_upper'] - df['bb_lower']) / df['bb_middle'],
            np.nan
        )
        
        # ğŸ†• KDJ Indicator (Specification requirement for 15m setup)
        # Parameters: N=9, M1=3, M2=3
        from ta.momentum import StochasticOscillator
        stoch = StochasticOscillator(
            high=df['high'],
            low=df['low'],
            close=df['close'],
            window=9,
            smooth_window=3
        )
        df['kdj_k'] = stoch.stoch()
        df['kdj_d'] = stoch.stoch_signal()
        df['kdj_j'] = 3 * df['kdj_k'] - 2 * df['kdj_d']
        
        
        # ATR (æ³¢åŠ¨ç‡) - ä¿®å¤å‰æœŸ 0 å€¼é—®é¢˜
        # å…ˆè®¡ç®— True Range
        df['prev_close'] = df['close'].shift(1)
        df['tr1'] = df['high'] - df['low']
        df['tr2'] = abs(df['high'] - df['prev_close'])
        df['tr3'] = abs(df['low'] - df['prev_close'])
        df['true_range'] = df[['tr1', 'tr2', 'tr3']].max(axis=1)
        
        # ä½¿ç”¨ ta åº“è®¡ç®— ATR
        atr_indicator = AverageTrueRange(
            high=df['high'],
            low=df['low'],
            close=df['close'],
            window=14
        )
        df['atr'] = atr_indicator.average_true_range()
        
        # ä¿®å¤å‰ 13 æ ¹ K çº¿çš„ ATR=0 é—®é¢˜
        # ç”¨å…¨å±€ True Range çš„ EMA æ¥å¡«å……ï¼ˆæ›´ç¨³å®šï¼‰
        mask = df['atr'] == 0
        if mask.any():
            # ä½¿ç”¨å…¨å±€ True Range çš„ EMA æ¥å¡«å……å‰æœŸå€¼
            tr_ema = df['true_range'].ewm(span=14, adjust=False).mean()
            df.loc[mask, 'atr'] = tr_ema[mask]
        
        # æ¸…ç†ä¸´æ—¶åˆ—
        df.drop(['prev_close', 'tr1', 'tr2', 'tr3', 'true_range'], axis=1, inplace=True)
        
        # æˆäº¤é‡æŒ‡æ ‡
        df['volume_sma'] = df['volume'].rolling(window=20).mean()
        # å®‰å…¨è®¡ç®— volume_ratioï¼Œé¿å…é™¤ä»¥0å’ŒNaN
        df['volume_ratio'] = np.where(
            (df['volume_sma'].notna()) & (df['volume_sma'] > 0),
            df['volume'] / df['volume_sma'],
            1.0  # é»˜è®¤å€¼1è¡¨ç¤ºæ­£å¸¸æ°´å¹³
        )
        
        # OBV (On Balance Volume)
        # OBV = ç´¯ç§¯çš„(æˆäº¤é‡ Ã— ä»·æ ¼æ–¹å‘)
        # ä»·æ ¼ä¸Šæ¶¨æ—¶åŠ æˆäº¤é‡ï¼Œä»·æ ¼ä¸‹è·Œæ—¶å‡æˆäº¤é‡
        df['obv'] = (df['volume'] * np.sign(df['close'].diff())).fillna(0).cumsum()
        
        # VWAP - ä½¿ç”¨20æœŸæ»šåŠ¨çª—å£ï¼ˆç¬¦åˆé‡åŒ–ç­–ç•¥éœ€æ±‚ï¼‰
        # ä¿®å¤åŸæœ‰å…¨å±€ç´¯ç§¯é€»è¾‘ï¼Œæ”¹ä¸ºæ»šåŠ¨çª—å£æ›´æœ‰å®é™…æ„ä¹‰
        window = 20
        df['price_volume'] = df['close'] * df['volume']
        rolling_pv = df['price_volume'].rolling(window=window).sum()
        rolling_vol = df['volume'].rolling(window=window).sum()
        
        # å®‰å…¨è®¡ç®— VWAPï¼Œé¿å…é™¤ä»¥0
        df['vwap'] = np.where(
            rolling_vol > 0,
            rolling_pv / rolling_vol,
            df['close']  # å¦‚æœæˆäº¤é‡ä¸º0ï¼Œç”¨closeä»£æ›¿
        )
        df.drop('price_volume', axis=1, inplace=True)
        
        # ä»·æ ¼å˜åŒ–
        df['price_change_pct'] = df['close'].pct_change() * 100
        # å®‰å…¨è®¡ç®—é«˜ä½ç‚¹æŒ¯å¹…ï¼Œé¿å…é™¤ä»¥0
        df['high_low_range'] = np.where(
            df['close'] > 0,
            (df['high'] - df['low']) / df['close'] * 100,
            0.0
        )
        
        return df
    
    def _mark_warmup_period(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ ‡è®°æŒ‡æ ‡ warm-up æœŸï¼Œå‰æœŸæŒ‡æ ‡ä¸ç¨³å®šçš„æ•°æ®åº”é¿å…ç”¨äºäº¤æ˜“å†³ç­–
        
        âœ… ä¿®æ­£ï¼šWarmup æœŸä» 50 æå‡åˆ° 105 æ ¹ï¼Œç¡®ä¿ MACD å®Œå…¨æ”¶æ•›
        
        è®¡ç®—é€»è¾‘ï¼ˆåŸºäº EMA æ”¶æ•›ç†è®ºï¼‰ï¼š
        - EMA æ”¶æ•›å…¬å¼ï¼šéœ€è¦ 3Ã—å‘¨æœŸ æ‰èƒ½è¾¾åˆ° 95% æƒé‡ç´¯ç§¯
        - EMA12: 3Ã—12 = 36 æ ¹
        - EMA26: 3Ã—26 = 78 æ ¹
        - MACD = EMA12 - EMA26ï¼Œéœ€è¦ 78 æ ¹æ‰ç¨³å®š
        - MACD Signal = EMA9(MACD)ï¼Œéœ€è¦é¢å¤– 3Ã—9 = 27 æ ¹
        - **MACD å®Œå…¨ç¨³å®šéœ€è¦ï¼š78 + 27 = 105 æ ¹**
        
        åŸé—®é¢˜ï¼š
        - å‰ 50 æ ¹æ ‡è®°ä¸º warmupï¼Œç¬¬ 51 æ ¹å³è®¤ä¸º is_valid=True
        - ä½†æ­¤æ—¶ MACD/Signal å°šæœªå®Œå…¨æ”¶æ•›ï¼Œæ•°å€¼æœ‰åå·®
        - å¯¼è‡´ Step4 è¶‹åŠ¿åˆ¤æ–­åŸºäºä¼ªç¨³å®šæ•°æ®ï¼Œäº§ç”Ÿé”™è¯¯ä¿¡å·
        
        ä¿®æ­£æ–¹æ¡ˆï¼š
        - Warmup æœŸæå‡è‡³ 105 æ ¹ï¼ˆä¿å®ˆç­–ç•¥ï¼‰
        - ç¬¬ 106 æ ¹åŠä»¥åæ‰æ ‡è®° is_valid=True
        - ç¡®ä¿æ‰€æœ‰æŠ€æœ¯æŒ‡æ ‡ï¼ˆSMA/EMA/MACD/RSI/ATRï¼‰å®Œå…¨ç¨³å®š
        
        Returns:
            æ·»åŠ  is_valid å’Œ is_warmup åˆ—çš„ DataFrame
        """
        # âœ… æ ¸å¿ƒä¿®æ­£ï¼šMACD å®Œå…¨æ”¶æ•›éœ€è¦ 105 æ ¹
        # è®¡ç®—æ–¹å¼ï¼šEMA26 æ”¶æ•›(78) + Signal EMA9 æ”¶æ•›(27) = 105
        WARMUP_PERIOD = 105  # âœ… ä» 50 æå‡è‡³ 105
        
        # ä¿ç•™åŸæœ‰é€»è¾‘ä½œä¸ºæœ€å°å€¼æ£€æŸ¥ï¼ˆé˜²å¾¡æ€§ç¼–ç¨‹ï¼‰
        min_bars_needed = max(
            max(self.INDICATOR_PARAMS['sma']),      # 50
            self.INDICATOR_PARAMS['macd']['slow'] + self.INDICATOR_PARAMS['macd']['signal'],  # 26 + 9 = 35
            self.INDICATOR_PARAMS['atr']['period']  # 14
        )
        
        # ä½¿ç”¨æ›´ä¸¥æ ¼çš„ WARMUP_PERIOD
        effective_warmup = max(min_bars_needed, WARMUP_PERIOD)  # ç»“æœå¿…ç„¶æ˜¯ 105
        
        # æ ‡è®° warmup æœŸï¼ˆå‰ effective_warmup æ ¹ï¼‰
        df['is_warmup'] = True
        df['is_valid'] = False
        
        if len(df) > effective_warmup:
            # âœ… åªæœ‰ç¬¬ 106 æ ¹åŠä»¥åçš„æ•°æ®æ‰æ˜¯æœ‰æ•ˆçš„ï¼ˆç´¢å¼• 105+ï¼‰
            df.iloc[effective_warmup:, df.columns.get_loc('is_warmup')] = False
            df.iloc[effective_warmup:, df.columns.get_loc('is_valid')] = True
            
        # è®°å½•æœ‰æ•ˆæ•°æ®çš„èµ·å§‹ç´¢å¼•
        self._min_valid_index = effective_warmup
        
        # æ—¥å¿—è¾“å‡º
        valid_count = df['is_valid'].sum()
        log.debug(
            f"âœ… Warm-upæ ‡è®°ï¼ˆä¿®æ­£ç‰ˆï¼‰: æ€»æ•°={len(df)}, "
            f"warm-upæœŸ={effective_warmup}æ ¹ï¼ˆMACDå®Œå…¨æ”¶æ•›ï¼‰, "
            f"æœ‰æ•ˆæ•°æ®={valid_count}æ ¹"
        )
        
        return df
    
    def _get_min_valid_index(self) -> int:
        """è·å–æœ€å°æœ‰æ•ˆç´¢å¼•ï¼ˆwarm-up è¾¹ç•Œï¼‰"""
        return getattr(self, '_min_valid_index', 50)  # é»˜è®¤ 50
    
    # === æ–°å¢è¾…åŠ©å‡½æ•°ï¼ˆæ­¥éª¤3ç›¸å…³ï¼‰ ===
    def _safe_div(self, numer: pd.Series, denom, eps: float = 1e-9, fill: float = 0.0) -> pd.Series:
        """å®‰å…¨é™¤æ³•ï¼Œé¿å…é™¤ä»¥0æˆ–éå¸¸å°æ•°å€¼å¯¼è‡´ inf/NaNã€‚

        denom å¯ä»¥æ˜¯ Seriesï¼Œä¹Ÿå¯ä»¥æ˜¯æ ‡é‡ï¼ˆfloat/intï¼‰ã€‚
        """
        if numer is None:
            return pd.Series(dtype=float)

        # å¤„ç†æ ‡é‡ denom
        if isinstance(denom, (int, float, np.floating, np.integer)):
            denom_safe = pd.Series(float(denom), index=numer.index)
        else:
            # å°è¯•å°† denom è½¬ä¸º Series
            denom_safe = pd.Series(denom, index=numer.index).astype(float)

        small = denom_safe.abs() < eps
        denom_safe[small] = eps
        res = numer.astype(float) / denom_safe
        res = res.where(~small, fill)
        return res

    def _winsorize(self, s: pd.Series, lower_q: float = 0.01, upper_q: float = 0.99) -> pd.Series:
        """æŒ‰åˆ†ä½æ•°æˆªæ–­æç«¯å€¼ï¼ˆéç ´åæ€§ï¼‰ã€‚"""
        if s.dropna().empty:
            return s
        lo = s.quantile(lower_q)
        hi = s.quantile(upper_q)
        return s.clip(lower=lo, upper=hi)

    def _check_time_gaps(self, df: pd.DataFrame, freq_minutes: int = 5, allowed_gap_bars: int = 2) -> Tuple[pd.DataFrame, pd.Series]:
        """æ£€æŸ¥å¹¶å¯¹å°çš„æ—¶é—´ç¼ºå£è¿›è¡Œæœ‰é™åˆ¶åœ°æ’å€¼å¡«å……ã€‚

        è¿”å›å€¼ï¼š (df_reindexed, imputed_mask)
        - df_reindexed: é‡æ–°ç´¢å¼•å¹¶åœ¨å° gap ä¸Šæ’å€¼åçš„ DataFrame
        - imputed_mask: å¸ƒå°” Series æ ‡è®°å“ªäº›è¡Œæ˜¯æ’å€¼äº§ç”Ÿçš„
        """
        if df.empty:
            return df.copy(), pd.Series(False, dtype=bool)

        start = df.index.min()
        end = df.index.max()
        full_index = pd.date_range(start=start, end=end, freq=f'{freq_minutes}min')
        df_re = df.reindex(full_index)

        # å°è¯•æ¨æ–­å¯¹è±¡ç±»å‹ä¸ºæ•°å€¼ï¼Œå‡å°‘ future warning
        try:
            df_re = df_re.infer_objects(copy=False)
        except Exception:
            pass

        # æ ‡è®°åŸå§‹ç¼ºå¤±ä½ç½®
        orig_na = df_re['close'].isna()

        # åªå¯¹å° gap è¿›è¡Œçº¿æ€§æ—¶é—´æ’å€¼ï¼ˆlimit=allowed_gap_barsï¼‰
        # ä½¿ç”¨ method='time' è¦æ±‚ DatetimeIndex
        # Fix: Ensure numeric types for interpolation to avoid FutureWarning
        cols_to_interpolate = df_re.select_dtypes(include=[np.number]).columns
        df_re[cols_to_interpolate] = df_re[cols_to_interpolate].interpolate(method='time', limit=allowed_gap_bars)

        # æ ‡è®°æ’å€¼æˆåŠŸçš„è¡Œï¼ˆåŸæœ¬æ˜¯NaNï¼Œç°åœ¨æœ‰å€¼ï¼‰
        imputed_mask = orig_na.astype(bool) & df_re['close'].notna().astype(bool)

        # è®°å½• imputed æ ‡è¯†ï¼ˆä¾¿äºä¸‹æ¸¸è¿‡æ»¤ï¼‰
        df_re['is_imputed'] = imputed_mask

        return df_re, imputed_mask

    def extract_feature_snapshot(
        self,
        df: pd.DataFrame,
        lookback: int = 48,
        min_fraction: float = 0.5,
        winsor_limits: Tuple[float, float] = (0.01, 0.99),
        freq_minutes: int = 5,
        allowed_gap_bars: int = 2,
        feature_version: str = 'v1'
    ) -> pd.DataFrame:
        """ä»å·²è®¡ç®—æŒ‡æ ‡çš„Kçº¿DataFrameä¸­æå–ç‰¹å¾å¿«ç…§ï¼ˆé€è¡Œæˆ–æœ€æ–°è¡Œï¼‰ã€‚

        è®¾è®¡åŸåˆ™ï¼š
        - ä¸åœ¨ç‰¹å¾è®¡ç®—ä¸­ä½¿ç”¨æœªæ¥æ•°æ®
        - å¯¹é™¤æ³•æ“ä½œè¿›è¡Œå®‰å…¨å¤„ç†
        - å¯¹å° gap å…è®¸æœ‰é™çš„æ’å€¼ï¼Œä½†æ ‡è®° is_imputed
        - è¾“å‡ºåŒ…å« feature_versionã€is_feature_validã€warm_up_bars_remaining
        """
        if df.empty:
            return pd.DataFrame()

        # 1) æ—¶é—´å¯¹é½ä¸å° gap å¤„ç†
        df_checked, imputed_mask = self._check_time_gaps(df, freq_minutes=freq_minutes, allowed_gap_bars=allowed_gap_bars)

        # 2) å‡†å¤‡çª—å£å‚æ•°
        L = int(lookback)
        min_periods = int(max(1, L * min_fraction))

        # 3) è®¡ç®—æ»šåŠ¨ç‰¹å¾ï¼ˆä½¿ç”¨æ»šåŠ¨çª—å£ï¼Œä¸ä½¿ç”¨æœªæ¥ä¿¡æ¯ï¼‰
        features = pd.DataFrame(index=df_checked.index)
        features['close'] = df_checked['close']
        features['volume'] = df_checked['volume']

        # returns & log returns
        features['return_pct'] = df_checked['close'].pct_change(fill_method=None) * 100
        # æ›¿æ¢ç”±é™¤ä»¥0äº§ç”Ÿçš„ inf
        features['return_pct'] = features['return_pct'].replace([np.inf, -np.inf], np.nan)
        # log on zeros will produce -inf; protect by replacing non-positive with NaN first
        safe_close = df_checked['close'].where(df_checked['close'] > 0)
        features['log_return'] = np.log(safe_close).diff()

        # é™åˆ¶æç«¯ return çš„ä¸Šé™ï¼Œé¿å…åç»­ winsorize å—æç«¯å€¼å½±å“è¿‡å¤§
        features['return_pct'] = features['return_pct'].clip(lower=-1e4, upper=1e4)

        # rolling volatility
        features['rolling_vol'] = features['return_pct'].rolling(window=L, min_periods=min_periods).std(ddof=0)
        features['rolling_mean_price'] = df_checked['close'].rolling(window=L, min_periods=min_periods).mean()
        features['rolling_median_price'] = df_checked['close'].rolling(window=L, min_periods=min_periods).median()

        # momentum
        features['momentum_1'] = df_checked['close'].pct_change(periods=1, fill_method=None)
        features['momentum_12'] = df_checked['close'].pct_change(periods=min(12, L), fill_method=None)

        # MACD/ATR/VWAP ç­‰ç›¸å¯¹å€¼ï¼ˆä½¿ç”¨å®‰å…¨é™¤æ³•ï¼‰
        # ä¿®å¤è¯´æ˜ï¼ˆ2025-12-18ï¼‰: MACDç°åœ¨ä¿å­˜ä¸ºåŸå§‹ä»·å·®ï¼ˆUSDTï¼‰ï¼Œåœ¨ç‰¹å¾å·¥ç¨‹æ—¶å½’ä¸€åŒ–
        if 'macd' in df_checked.columns:
            # å½’ä¸€åŒ–ä¸ºç™¾åˆ†æ¯”ï¼ˆä¾›æ¨¡å‹è®­ç»ƒä½¿ç”¨ï¼‰
            features['macd_pct'] = self._safe_div(df_checked['macd'], df_checked['close']) * 100
        else:
            features['macd_pct'] = pd.Series(np.nan, index=df_checked.index)

        if 'macd_signal' in df_checked.columns:
            features['macd_signal_pct'] = self._safe_div(df_checked['macd_signal'], df_checked['close']) * 100
        else:
            features['macd_signal_pct'] = pd.Series(np.nan, index=df_checked.index)

        if 'macd_diff' in df_checked.columns:
            features['macd_diff_pct'] = self._safe_div(df_checked['macd_diff'], df_checked['close']) * 100
        else:
            features['macd_diff_pct'] = pd.Series(np.nan, index=df_checked.index)

        features['atr_pct'] = self._safe_div(df_checked.get('atr', pd.Series(np.nan, index=df_checked.index)), df_checked['close']) * 100

        # VWAP relative
        features['vwap_rel'] = self._safe_div(df_checked['close'] - df_checked.get('vwap', df_checked['close']), df_checked.get('vwap', df_checked['close']))

        # Bollinger width relative to rolling_mean_price
        features['bb_width_pct'] = self._safe_div(df_checked.get('bb_width', pd.Series(np.nan, index=df_checked.index)), 1.0) * 100
        # high_low_range å·²æ˜¯ç™¾åˆ†æ¯”åœ¨ _calculate_indicators ä¸­å¤„ç†
        features['high_low_range_pct'] = df_checked.get('high_low_range', df_checked['high'] - df_checked['low'])

        # volume z-score ï¼ˆä½¿ç”¨çª—å£å†…å‡å€¼å’Œstdï¼‰
        rolling_vol_mean = df_checked['volume'].rolling(window=L, min_periods=min_periods).mean()
        rolling_vol_std = df_checked['volume'].rolling(window=L, min_periods=min_periods).std(ddof=0)
        features['volume_z'] = self._safe_div(df_checked['volume'] - rolling_vol_mean, rolling_vol_std, fill=0.0)

        # volume ratio safe
        features['volume_ratio'] = df_checked.get('volume_ratio', pd.Series(1.0, index=df_checked.index)).fillna(1.0)

        # winsorize æŸäº›æç«¯ç‰¹å¾
        for col in ['return_pct', 'log_return', 'momentum_1', 'momentum_12', 'volume_z']:
            if col in features.columns:
                features[col] = self._winsorize(features[col], lower_q=winsor_limits[0], upper_q=winsor_limits[1])

        # å…¨å±€æ›¿æ¢ inf ä¸º NaNï¼Œä¿è¯ downstream ä¸ä¼šé‡åˆ° inf
        features.replace([np.inf, -np.inf], np.nan, inplace=True)

        # 4) æ ‡è®°ç‰¹å¾æœ‰æ•ˆæ€§
        # æ¡ä»¶ï¼šåŸå§‹ is_valid ä¸º Trueï¼ˆwarm-upå·²é€šè¿‡ï¼‰ã€çª—å£å†…æœ‰æ•ˆæ ·æœ¬ >= min_periodsã€å…³é”®å­—æ®µéNaN
        critical_cols = ['close', 'volume', 'macd_pct', 'atr_pct']
        has_critical = features[critical_cols].notna().all(axis=1)

        # åˆ¤æ–­çª—å£è¿ç»­æ€§ï¼šè®¡ç®—çª—å£å†…æœ‰æ•ˆè®¡æ•°
        window_count = features['close'].rolling(window=L, min_periods=1).count()
        has_enough_history = window_count >= min_periods

        # åˆæˆ is_feature_valid
        src_is_valid = df_checked.get('is_valid') if 'is_valid' in df_checked.columns else pd.Series(True, index=features.index)
        is_feature_valid = src_is_valid.fillna(False) & has_critical & has_enough_history & (~df_checked.get('is_imputed', pd.Series(False, index=features.index)))

        features['is_feature_valid'] = is_feature_valid

        # 5) warm_up_bars_remaining
        # è®¡ç®—åˆ°è¾¾ full lookback è¿˜å·®å¤šå°‘æ¡ï¼ˆåŸºäºå½“å‰æœ«å°¾éç¼ºå¤±è®¡æ•°ï¼‰
        recent_counts = features['close'].rolling(window=L, min_periods=1).count()
        features['warm_up_bars_remaining'] = (L - recent_counts).clip(lower=0).astype(int)

        # 6) æ³¨å…¥å…ƒæ•°æ®ä¸ç‰ˆæœ¬ä¿¡æ¯
        features['feature_version'] = feature_version
        # ä½¿ç”¨ä¼ å…¥DataFrameçš„ snapshot_id ä½œä¸º source referenceï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        source_ids = df_checked.get('snapshot_id', pd.Series(self.last_snapshot_id or 'unknown', index=features.index))
        features['source_snapshot_id'] = source_ids
        features['processor_version'] = self.PROCESSOR_VERSION
        # ä¿ç•™æ’å€¼æ ‡è®°ä»¥ä¾¿å®¡è®¡/æµ‹è¯•
        features['is_imputed'] = df_checked.get('is_imputed', pd.Series(False, index=features.index))

        # 7) ä»…è¿”å›æœ€æ–°è¡Œçš„ snapshotï¼ˆè°ƒç”¨æ–¹å¯é€‰æ‹©ä¿ç•™å…¨è¡¨ï¼‰
        # ä¿ç•™å®Œæ•´DataFrameä»¥ä¾¿å›æµ‹/å®¡è®¡ï¼Œä½†å¸¸ç”¨åœºæ™¯ä¼šå–å°¾è¡Œ
        return features

    def detect_trend(self, df: pd.DataFrame) -> str:
        """
        åˆ¤æ–­è¶‹åŠ¿
        
        Returns:
            'strong_uptrend', 'uptrend', 'sideways', 'downtrend', 'strong_downtrend'
        """
        if df.empty or len(df) < 50:
            return 'unknown'
        
        latest = df.iloc[-1]
        
        # ä½¿ç”¨å¤šé‡æŒ‡æ ‡åˆ¤æ–­
        conditions = []
        
        # 1. å‡çº¿æ’åˆ—
        if latest['close'] > latest['sma_20'] > latest['sma_50']:
            conditions.append(2)
        elif latest['close'] > latest['sma_20']:
            conditions.append(1)
        elif latest['close'] < latest['sma_20'] < latest['sma_50']:
            conditions.append(-2)
        elif latest['close'] < latest['sma_20']:
            conditions.append(-1)
        else:
            conditions.append(0)
        
        # 2. MACD
        if latest['macd'] > latest['macd_signal'] and latest['macd'] > 0:
            conditions.append(1)
        elif latest['macd'] < latest['macd_signal'] and latest['macd'] < 0:
            conditions.append(-1)
        else:
            conditions.append(0)
        
        # 3. ä»·æ ¼ç›¸å¯¹å¸ƒæ—å¸¦ä½ç½®
        if latest['close'] > latest['bb_upper']:
            conditions.append(1)
        elif latest['close'] < latest['bb_lower']:
            conditions.append(-1)
        else:
            conditions.append(0)
        
        # ç»¼åˆè¯„åˆ†
        score = sum(conditions)
        
        if score >= 3:
            return 'strong_uptrend'
        elif score >= 1:
            return 'uptrend'
        elif score <= -3:
            return 'strong_downtrend'
        elif score <= -1:
            return 'downtrend'
        else:
            return 'sideways'
    
    def detect_volatility(self, df: pd.DataFrame) -> str:
        """
        åˆ¤æ–­æ³¢åŠ¨ç‡
        
        Returns:
            'low', 'normal', 'high', 'extreme'
        """
        if df.empty or len(df) < 20:
            return 'unknown'
        
        latest = df.iloc[-1]
        
        # ä½¿ç”¨ATRå’Œå¸ƒæ—å¸¦å®½åº¦
        atr_pct = latest['atr'] / latest['close'] * 100
        bb_width = latest['bb_width'] * 100
        
        # å†å²åˆ†ä½æ•°
        atr_percentile = (df['atr'] / df['close'] * 100).rank(pct=True).iloc[-1]
        
        if atr_percentile > 0.9 or bb_width > 5:
            return 'extreme'
        elif atr_percentile > 0.7 or bb_width > 3:
            return 'high'
        elif atr_percentile < 0.3:
            return 'low'
        else:
            return 'normal'
    
    def detect_momentum(self, df: pd.DataFrame) -> str:
        """
        åˆ¤æ–­åŠ¨é‡
        
        Returns:
            'strong', 'moderate', 'weak', 'negative'
        """
        if df.empty or len(df) < 50:
            return 'unknown'
        
        latest = df.iloc[-1]
        
        # RSI
        rsi = latest['rsi']
        
        # MACDå¼ºåº¦
        macd_strength = abs(latest['macd_diff'])
        macd_avg = df['macd_diff'].abs().rolling(20).mean().iloc[-1]
        
        # ä»·æ ¼åŠ¨é‡
        price_momentum = df['close'].pct_change(10).iloc[-1] * 100
        
        if rsi > 70 and macd_strength > macd_avg and price_momentum > 5:
            return 'strong'
        elif rsi > 60 and price_momentum > 2:
            return 'moderate'
        elif rsi < 30 and price_momentum < -5:
            return 'negative'
        else:
            return 'weak'
    
    def find_support_resistance(
        self, 
        df: pd.DataFrame, 
        lookback: int = 50,
        max_distance_pct: float = 0.50  # æœ€å¤§è·ç¦»50%
    ) -> Dict:
        """
        å¯»æ‰¾æ”¯æ’‘ä½å’Œé˜»åŠ›ä½ï¼ˆå¸¦å¼‚å¸¸è¿‡æ»¤ï¼‰
        
        æ–¹æ³•ï¼š
        - ä½¿ç”¨è¿‘æœŸé«˜ä½ç‚¹
        - ä½¿ç”¨å¸ƒæ—å¸¦ä¸Šä¸‹è½¨
        - è¿‡æ»¤è·ç¦»å½“å‰ä»·æ ¼è¿‡è¿œçš„å¼‚å¸¸å€¼
        
        Args:
            df: Kçº¿æ•°æ®
            lookback: å›æº¯å‘¨æœŸ
            max_distance_pct: æœ€å¤§è·ç¦»ç™¾åˆ†æ¯”ï¼ˆè¿‡æ»¤å¼‚å¸¸å€¼ï¼‰
            
        Returns:
            {
                'support': [ä»·æ ¼åˆ—è¡¨],
                'resistance': [ä»·æ ¼åˆ—è¡¨],
                'method': 'è®¡ç®—æ–¹æ³•è¯´æ˜',
                'lookback': å›æº¯å‘¨æœŸ
            }
        """
        if df.empty or len(df) < lookback:
            return {
                'support': [],
                'resistance': [],
                'method': 'insufficient_data',
                'lookback': 0
            }
        
        recent_df = df.tail(lookback)
        current_price = df['close'].iloc[-1]
        latest = df.iloc[-1]
        
        # å¯»æ‰¾å±€éƒ¨é«˜ç‚¹å’Œä½ç‚¹
        highs = recent_df['high'].values
        lows = recent_df['low'].values
        
        resistance_levels = []
        support_levels = []
        
        # 1. å†å²é«˜ä½ç‚¹
        recent_high = np.max(highs)
        recent_low = np.min(lows)
        
        # è¿‡æ»¤å¼‚å¸¸å€¼ï¼šè·ç¦»å½“å‰ä»·æ ¼ä¸è¶…è¿‡ max_distance_pct
        max_distance_up = current_price * (1 + max_distance_pct)
        max_distance_down = current_price * (1 - max_distance_pct)
        
        # åªæ·»åŠ åˆç†èŒƒå›´å†…çš„ä»·ä½
        if recent_high > current_price and recent_high < max_distance_up:
            resistance_levels.append(float(round(recent_high, 2)))
        
        if recent_low < current_price and recent_low > max_distance_down:
            support_levels.append(float(round(recent_low, 2)))
        
        # 2. å¸ƒæ—å¸¦ä½œä¸ºåŠ¨æ€æ”¯æ’‘é˜»åŠ›
        bb_upper = latest['bb_upper']
        bb_lower = latest['bb_lower']
        
        # å¸ƒæ—å¸¦é€šå¸¸æ¯”è¾ƒåˆç†ï¼Œä½†ä¹Ÿè¦æ£€æŸ¥
        if bb_upper < max_distance_up:
            resistance_levels.append(float(round(bb_upper, 2)))
        
        if bb_lower > max_distance_down:
            support_levels.append(float(round(bb_lower, 2)))
        
        # å»é‡å¹¶æ’åº
        support_levels = sorted(list(set(support_levels)))
        resistance_levels = sorted(list(set(resistance_levels)), reverse=True)
        
        return {
            'support': support_levels,
            'resistance': resistance_levels,
            'method': f'swing_highs_lows+bollinger, lookback={lookback}, max_distance={max_distance_pct:.0%}',
            'lookback': lookback,
            'filtered': {
                'high_filtered': recent_high >= max_distance_up,
                'low_filtered': recent_low <= max_distance_down
            }
        }
    
    def check_indicator_completeness(self, df: pd.DataFrame, min_coverage: float = 0.95) -> Dict:
        """
        æ£€æŸ¥æŠ€æœ¯æŒ‡æ ‡å®Œæ•´æ€§
        
        æ£€æŸ¥é¡¹:
        1. å…³é”®æŒ‡æ ‡æ˜¯å¦åŒ…å« NaN/Inf
        2. æ•°æ®è¦†ç›–ç‡æ˜¯å¦è¾¾æ ‡
        3. warm-upæœŸæ˜¯å¦å®Œæˆ
        
        Args:
            df: åŒ…å«æŠ€æœ¯æŒ‡æ ‡çš„DataFrame
            min_coverage: æœ€å°è¦†ç›–ç‡é˜ˆå€¼ï¼ˆé»˜è®¤95%ï¼‰
            
        Returns:
            {
                'is_complete': bool,
                'issues': List[str],
                'coverage': Dict[str, float],
                'overall_coverage': float
            }
        """
        if df.empty:
            return {
                'is_complete': False,
                'issues': ['DataFrameä¸ºç©º'],
                'coverage': {},
                'overall_coverage': 0.0
            }
        
        # å…³é”®æŒ‡æ ‡åˆ—è¡¨
        critical_indicators = [
            'sma_20', 'sma_50', 'ema_12', 'ema_26',
            'macd', 'macd_signal', 'macd_diff',
            'rsi', 'bb_upper', 'bb_middle', 'bb_lower',
            'atr', 'volume_sma', 'volume_ratio'
        ]
        
        issues = []
        coverage = {}
        
        # 1. æ£€æŸ¥æ¯ä¸ªæŒ‡æ ‡çš„å®Œæ•´æ€§
        for indicator in critical_indicators:
            if indicator not in df.columns:
                issues.append(f'{indicator} ç¼ºå¤±')
                coverage[indicator] = 0.0
                continue
            
            series = df[indicator]
            
            # æ£€æŸ¥ NaN
            nan_count = series.isna().sum()
            nan_pct = nan_count / len(series)
            
            # æ£€æŸ¥ Inf
            inf_count = np.isinf(series).sum() if series.dtype in [np.float32, np.float64] else 0
            
            # è®¡ç®—è¦†ç›–ç‡
            valid_count = len(series) - nan_count - inf_count
            indicator_coverage = valid_count / len(series) if len(series) > 0 else 0.0
            coverage[indicator] = indicator_coverage
            
            # è®°å½•é—®é¢˜
            if nan_count > 0:
                issues.append(f'{indicator} åŒ…å« {nan_count} ä¸ªNaNå€¼ (è¦†ç›–ç‡: {indicator_coverage:.1%})')
            if inf_count > 0:
                issues.append(f'{indicator} åŒ…å« {inf_count} ä¸ªInfå€¼')
        
        # 2. æ£€æŸ¥ warm-up çŠ¶æ€
        if 'is_valid' in df.columns:
            valid_bars = df['is_valid'].sum()
            valid_ratio = valid_bars / len(df) if len(df) > 0 else 0.0
            
            if valid_ratio < min_coverage:
                issues.append(
                    f'warm-upæœŸæœªå®Œæˆ: æœ‰æ•ˆæ•°æ®å æ¯”={valid_ratio:.1%} < {min_coverage:.1%}'
                )
        else:
            issues.append('ç¼ºå°‘ is_valid æ ‡è®°')
        
        # 3. è®¡ç®—æ€»ä½“è¦†ç›–ç‡
        if coverage:
            overall_coverage = sum(coverage.values()) / len(coverage)
        else:
            overall_coverage = 0.0
        
        # 4. åˆ¤æ–­æ˜¯å¦å®Œæ•´
        is_complete = (
            len(issues) == 0 and
            overall_coverage >= min_coverage
        )
        
        return {
            'is_complete': is_complete,
            'issues': issues,
            'coverage': coverage,
            'overall_coverage': overall_coverage
        }
