"""
ğŸ”® Prophet ML Model
===========================================

åŸºäº LightGBM çš„ä»·æ ¼é¢„æµ‹æ¨¡å‹
Label: æœªæ¥ 30 åˆ†é’Ÿä»·æ ¼æ˜¯å¦ä¸Šæ¶¨ (æ¶¨å¹… > 0.1%)

Author: AI Trader Team
Date: 2025-12-21
"""

import os
import pickle
from typing import Dict, List, Optional, Tuple
from datetime import datetime
import numpy as np
import pandas as pd

from src.agents.predict_agent import PredictAgent
from src.utils.logger import log

# å°è¯•å¯¼å…¥ LightGBM
try:
    import lightgbm as lgb
    HAS_LIGHTGBM = True
except (ImportError, OSError):
    HAS_LIGHTGBM = False
    log.warning("LightGBM not installed, will use rule-based scoring mode")


class ProphetMLModel:
    """
    Prophet ä»·æ ¼é¢„æµ‹ ML æ¨¡å‹
    
    ç‰¹ç‚¹:
    - ä½¿ç”¨ LightGBM äºŒåˆ†ç±»æ¨¡å‹
    - Label: æœªæ¥ 30 åˆ†é’Ÿä»·æ ¼ä¸Šæ¶¨ (æ¶¨å¹… > 0.1%)
    - è¾“å‡º: ä¸Šæ¶¨æ¦‚ç‡ P(up)
    """
    
    # é»˜è®¤æ¨¡å‹å‚æ•°
    DEFAULT_PARAMS = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'boosting_type': 'gbdt',
        
        # ğŸ”§ Balanced Model Complexity (Improved from too simple)
        'num_leaves': 20,              # Increased from 10 (allow more patterns)
        'max_depth': 6,                # Increased from 4 (deeper trees for complex patterns)
        'min_child_samples': 20,       # Keep at 20 (good balance)
        'min_child_weight': 0.001,     # Keep (prevents overfitting on outliers)
        
        # ğŸ”§ Moderate Regularization (Reduced from too strong)
        'lambda_l1': 0.1,              # Reduced from 0.5 (less penalty)
        'lambda_l2': 0.1,              # Reduced from 0.5 (less penalty)
        'min_gain_to_split': 0.01,    # Reduced from 0.02 (easier to split)
        
        # ğŸ”§ Learning Rate & Iterations (Optimized)
        'learning_rate': 0.05,         # Increased from 0.02 (faster learning)
        'n_estimators': 200,           # Increased from 100 (more trees for better fit)
        
        # ğŸ”§ Sampling (Moderate)
        'feature_fraction': 0.8,       # Increased from 0.7 (use more features)
        'bagging_fraction': 0.8,       # Increased from 0.7 (use more samples)
        'bagging_freq': 5,
        
        # Training
        'early_stopping_rounds': 30,   # Keep at 30
        'verbose': -1,
        
        # ğŸ”§ Additional boosting parameters for better performance
        'max_bin': 255,                # Default, good for most cases
        'min_data_in_bin': 3,          # Minimum data in one bin
    }
    
    # é¢„æµ‹æ‰€éœ€çš„æ ¸å¿ƒç‰¹å¾åˆ—è¡¨
    REQUIRED_FEATURES = [
        'rsi',
        'bb_position',
        'trend_confirmation_score',
        'ema_cross_strength',
        'sma_cross_strength',
        'volume_ratio',
        'momentum_acceleration',
        'atr_normalized',
        'price_to_sma20_pct',
        'macd_momentum_5',
        'rsi_momentum_5',
        'obv_trend',
        'volatility_20',
    ]
    
    # Label å®šä¹‰ (Multi-class Trend Direction)
    PREDICTION_HORIZON_MINUTES = 180  # 3 hours (clearer trends)
    STRONG_THRESHOLD = 0.015  # 1.5% for strong moves
    WEAK_THRESHOLD = 0.005    # 0.5% for weak moves
    def __init__(self, model_path: Optional[str] = None, symbol: str = 'BTCUSDT'):
        """
        åˆå§‹åŒ– Prophet ML æ¨¡å‹
        
        Args:
            model_path: é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„ (å¯é€‰)
            symbol: äº¤æ˜“å¯¹ç¬¦å· (ç”¨äºç”Ÿæˆæ¨¡å‹æ–‡ä»¶å)
        """
        self.model = None
        self.symbol = symbol
        # ç”Ÿæˆ symbol-specific æ¨¡å‹è·¯å¾„
        default_path = f'models/prophet_lgb_{symbol}.pkl'
        self.model_path = model_path or default_path
        self.feature_names: List[str] = []
        self.is_trained = False
        
        # å°è¯•åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
        if model_path and os.path.exists(model_path):
            self.load(model_path)
        elif os.path.exists(self.model_path):
            self.load(self.model_path)
    
    def train(
        self,
        X_train: pd.DataFrame,
        y_train: pd.Series,
        X_val: Optional[pd.DataFrame] = None,
        y_val: Optional[pd.Series] = None,
        params: Optional[Dict] = None
    ) -> Dict:
        """
        è®­ç»ƒæ¨¡å‹
        
        Args:
            X_train: è®­ç»ƒç‰¹å¾ DataFrame
            y_train: è®­ç»ƒæ ‡ç­¾ Series (0 æˆ– 1)
            X_val: éªŒè¯ç‰¹å¾ (å¯é€‰)
            y_val: éªŒè¯æ ‡ç­¾ (å¯é€‰)
            params: æ¨¡å‹å‚æ•° (å¯é€‰)
        
        Returns:
            è®­ç»ƒæŒ‡æ ‡å­—å…¸
        """
        if not HAS_LIGHTGBM:
            raise ImportError("LightGBM not installed, please run: pip install lightgbm")
        
        # ä½¿ç”¨é»˜è®¤å‚æ•°æˆ–è‡ªå®šä¹‰å‚æ•°
        model_params = {**self.DEFAULT_PARAMS, **(params or {})}
        
        # ä¿å­˜ç‰¹å¾å
        self.feature_names = list(X_train.columns)
        
        log.info(f"ğŸ”® å¼€å§‹è®­ç»ƒ Prophet ML æ¨¡å‹...")
        log.info(f"   è®­ç»ƒæ ·æœ¬: {len(X_train)}, ç‰¹å¾æ•°: {len(self.feature_names)}")
        
        # å¤„ç†éªŒè¯é›†
        eval_set = None
        if X_val is not None and y_val is not None:
            eval_set = [(X_val, y_val)]
            log.info(f"   éªŒè¯æ ·æœ¬: {len(X_val)}")
        
        # è®­ç»ƒ LightGBM æ¨¡å‹
        self.model = lgb.LGBMClassifier(**model_params)
        
        if eval_set:
            self.model.fit(
                X_train, y_train,
                eval_set=eval_set,
            )
        else:
            self.model.fit(X_train, y_train)
        
        self.is_trained = True
        
        # è®¡ç®—è®­ç»ƒæŒ‡æ ‡
        train_pred = self.model.predict_proba(X_train)[:, 1]
        train_auc = self._calculate_auc(y_train, train_pred)
        
        metrics = {
            'train_samples': len(X_train),
            'train_auc': train_auc,
            'n_features': len(self.feature_names),
            'model_type': 'lightgbm',
        }
        
        if X_val is not None and y_val is not None:
            val_pred = self.model.predict_proba(X_val)[:, 1]
            val_auc = self._calculate_auc(y_val, val_pred)
            metrics['val_samples'] = len(X_val)
            metrics['val_auc'] = val_auc
            self.val_auc_score = val_auc  # Store for runtime usage
        else:
            self.val_auc_score = 0.5
        
        log.info(f"   âœ… è®­ç»ƒå®Œæˆ! AUC: {train_auc:.4f}")
        
        return metrics

    @property
    def val_auc(self) -> float:
        """è·å–éªŒè¯é›† AUC åˆ†æ•°"""
        return getattr(self, 'val_auc_score', 0.5)
    
    def predict_proba(self, features: Dict[str, float]) -> Dict[str, float]:
        """
        é¢„æµ‹å¤šåˆ†ç±»æ¦‚ç‡ (Multi-class Trend Direction)
        
        Args:
            features: ç‰¹å¾å­—å…¸
        
        Returns:
            Dict with probabilities for each class:
            {
                'strong_down': float,  # P(class=-2)
                'weak_down': float,    # P(class=-1)
                'neutral': float,      # P(class=0)
                'weak_up': float,      # P(class=1)
                'strong_up': float,    # P(class=2)
            }
        """
        if not self.is_trained or self.model is None:
            raise ValueError("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè°ƒç”¨ train() æˆ– load()")
        
        # æ„å»ºç‰¹å¾å‘é‡
        feature_vector = self._prepare_features(features)
        
        # é¢„æµ‹æ¦‚ç‡ (5 classes)
        probs = self.model.predict_proba(feature_vector)[0]
        
        # Map to class names
        # LightGBM multiclass uses 0-indexed classes, but our labels are -2 to 2
        # We need to map: class 0 â†’ -2, class 1 â†’ -1, class 2 â†’ 0, class 3 â†’ 1, class 4 â†’ 2
        return {
            'strong_down': float(probs[0]),  # class -2 â†’ index 0
            'weak_down': float(probs[1]),    # class -1 â†’ index 1
            'neutral': float(probs[2]),      # class 0 â†’ index 2
            'weak_up': float(probs[3]),      # class 1 â†’ index 3
            'strong_up': float(probs[4]),    # class 2 â†’ index 4
        }
    
    def _prepare_features(self, features: Dict[str, float]) -> pd.DataFrame:
        """
        å‡†å¤‡ç‰¹å¾å‘é‡
        
        Args:
            features: åŸå§‹ç‰¹å¾å­—å…¸
        
        Returns:
            DataFrame æ ¼å¼çš„ç‰¹å¾å‘é‡
        """
        # ä½¿ç”¨è®­ç»ƒæ—¶çš„ç‰¹å¾é¡ºåº
        feature_names = self.feature_names if self.feature_names else self.REQUIRED_FEATURES
        
        feature_values = []
        for name in feature_names:
            value = features.get(name, 0.0)
            # å¤„ç†å¼‚å¸¸å€¼
            if value is None or (isinstance(value, float) and np.isnan(value)):
                value = 0.0
            elif isinstance(value, float) and np.isinf(value):
                value = 100.0 if value > 0 else -100.0
            feature_values.append(float(value))
        
        return pd.DataFrame([feature_values], columns=feature_names)
    
    def _calculate_auc(self, y_true: pd.Series, y_pred: np.ndarray) -> float:
        """è®¡ç®— AUC åˆ†æ•° (å¤šåˆ†ç±»ä½¿ç”¨ macro-average)"""
        try:
            from sklearn.metrics import roc_auc_score
            # For multiclass, use one-vs-rest with macro average
            # y_pred should be probabilities (n_samples, n_classes)
            return roc_auc_score(y_true, y_pred, multi_class='ovr', average='macro')
        except Exception as e:
            # Fallback: use accuracy as proxy
            try:
                from sklearn.metrics import accuracy_score
                y_pred_class = np.argmax(y_pred, axis=1) if len(y_pred.shape) > 1 else y_pred
                # Map back to original labels: 0â†’-2, 1â†’-1, 2â†’0, 3â†’1, 4â†’2
                y_pred_class = y_pred_class - 2
                return accuracy_score(y_true, y_pred_class)
            except:
                return 0.0
    
    def save(self, path: Optional[str] = None):
        """
        ä¿å­˜æ¨¡å‹
        
        Args:
            path: ä¿å­˜è·¯å¾„
        """
        save_path = path or self.model_path
        
        # ç¡®ä¿ç›®å½•å­˜åœ¨
        os.makedirs(os.path.dirname(save_path), exist_ok=True)
        
        # ä¿å­˜æ¨¡å‹å’Œç‰¹å¾å
        model_data = {
            'model': self.model,
            'feature_names': self.feature_names,
            'is_trained': self.is_trained,
            'val_auc': getattr(self, 'val_auc_score', 0.5), # Persist AUC
            'saved_at': datetime.now().isoformat(),
        }
        
        with open(save_path, 'wb') as f:
            pickle.dump(model_data, f)
        
        log.info(f"âœ… æ¨¡å‹å·²ä¿å­˜: {save_path}")
    
    def load(self, path: str):
        """
        åŠ è½½æ¨¡å‹
        
        Args:
            path: æ¨¡å‹æ–‡ä»¶è·¯å¾„
        """
        if not os.path.exists(path):
            raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {path}")
        
        with open(path, 'rb') as f:
            model_data = pickle.load(f)
            
        self.model = model_data['model']
        self.feature_names = model_data['feature_names']
        self.is_trained = model_data.get('is_trained', True)
        self.val_auc_score = model_data.get('val_auc', 0.5) # Load AUC
        self.model_path = path
        log.info(f"âœ… æ¨¡å‹å·²åŠ è½½: {path}")
    
    def get_feature_importance(self) -> Dict[str, float]:
        """
        è·å–ç‰¹å¾é‡è¦æ€§
        
        Returns:
            ç‰¹å¾å -> é‡è¦æ€§åˆ†æ•°
        """
        if not self.is_trained or self.model is None:
            return {}
        
        importance = self.model.feature_importances_
        return dict(zip(self.feature_names, importance))


class LabelGenerator:
    """
    æ ‡ç­¾ç”Ÿæˆå™¨
    
    æ ¹æ®æœªæ¥ 30 åˆ†é’Ÿä»·æ ¼å˜åŒ–ç”Ÿæˆè®­ç»ƒæ ‡ç­¾
    """
    
    def __init__(
        self,
        horizon_minutes: int = 30,
        up_threshold: float = 0.001
    ):
        """
        åˆå§‹åŒ–æ ‡ç­¾ç”Ÿæˆå™¨
        
        Args:
            horizon_minutes: é¢„æµ‹æ—¶é—´èŒƒå›´ (åˆ†é’Ÿ)
            up_threshold: ä¸Šæ¶¨é˜ˆå€¼ (0.001 = 0.1%)
        """
        self.horizon_minutes = horizon_minutes
        self.up_threshold = 0.001  # 0.1% threshold for binary classification
        self.up_threshold = up_threshold
    
    def generate_labels(self, df: pd.DataFrame, price_col: str = 'close') -> pd.Series:
        """
        ç”ŸæˆäºŒåˆ†ç±»æ ‡ç­¾ (Binary Classification: UP vs DOWN)
        
        Args:
            df: åŒ…å«ä»·æ ¼æ•°æ®çš„ DataFrame (éœ€è¦æœ‰æ—¶é—´ç´¢å¼•)
            price_col: ä»·æ ¼åˆ—å
        
        Returns:
            æ ‡ç­¾ Series:
            0: DOWN (price decrease or neutral)
            1: UP (price increase > threshold)
        """
        # è®¡ç®—æœªæ¥ä»·æ ¼ (å‘å‰ç§»åŠ¨ horizon ä¸ªå‘¨æœŸ)
        periods = self.horizon_minutes // 5  # å‡è®¾ 5 åˆ†é’Ÿ K çº¿
        
        if periods < 1:
            periods = 1
        
        # æœªæ¥ä»·æ ¼
        future_price = df[price_col].shift(-periods)
        
        # è®¡ç®—æ”¶ç›Šç‡
        returns = (future_price - df[price_col]) / df[price_col]
        
        # ç”ŸæˆäºŒåˆ†ç±»æ ‡ç­¾ (UP = 1, DOWN = 0)
        # Threshold: 0.1% (same as original UP_THRESHOLD)
        labels = (returns > self.up_threshold).astype(int)
        
        return labels

    def prepare_training_data(
        self,
        features_df: pd.DataFrame,
        price_df: pd.DataFrame,
        price_col: str = 'close'
    ) -> Tuple[pd.DataFrame, pd.Series]:
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®
        
        Args:
            features_df: ç‰¹å¾ DataFrame
            price_df: ä»·æ ¼ DataFrame (ç”¨äºç”Ÿæˆæ ‡ç­¾)
            price_col: ä»·æ ¼åˆ—å
        
        Returns:
            (X, y) å…ƒç»„
        """
        # ç”Ÿæˆæ ‡ç­¾
        labels = self.generate_labels(price_df, price_col)
        
        # å¯¹é½æ•°æ®
        common_idx = features_df.index.intersection(labels.index)
        X = features_df.loc[common_idx]
        y = labels.loc[common_idx]
        
        # ç§»é™¤ NaN
        valid_mask = ~(X.isna().any(axis=1) | y.isna())
        X = X[valid_mask]
        y = y[valid_mask]
        
        log.info(f"ğŸ“Š è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ: {len(X)} æ ·æœ¬")
        # Binary classification distribution
        up_count = (y == 1).sum()
        down_count = (y == 0).sum()
        log.info(f"   ä¸Šæ¶¨æ ·æœ¬: {up_count} ({up_count/len(y)*100:.1f}%)")
        log.info(f"   ä¸‹è·Œæ ·æœ¬: {down_count} ({down_count/len(y)*100:.1f}%)")

        return X, y


class ProphetAutoTrainer:
    """
    Prophet ML æ¨¡å‹è‡ªåŠ¨è®­ç»ƒå™¨
    
    æ¯éš”æŒ‡å®šæ—¶é—´è‡ªåŠ¨é‡æ–°è®­ç»ƒæ¨¡å‹
    """
    
    def __init__(
        self,
        binance_client,
        interval_hours: float = 2.0,
        training_days: int = 70,  # 10x samples (70 days)
    ):
        """
        åˆå§‹åŒ–è‡ªåŠ¨è®­ç»ƒå™¨
        
        Args:
            binance_client: BinanceClient å®ä¾‹
            interval_hours: è®­ç»ƒé—´éš” (å°æ—¶)
            training_days: ä½¿ç”¨çš„å†å²æ•°æ®å¤©æ•°
        """
        self.client = binance_client
        self.interval_hours = interval_hours
        self.training_days = training_days
        
        self._running = False
        self._thread = None
        self.last_train_time = None
        self.train_count = 0
        
    def start(
        self,
        predict_agent: PredictAgent,
        symbol: str = 'BTCUSDT'
    ):
        """å¯åŠ¨è‡ªåŠ¨è®­ç»ƒçº¿ç¨‹"""
        import threading
        
        if self._running:
            log.warning("è‡ªåŠ¨è®­ç»ƒå™¨å·²åœ¨è¿è¡Œ")
            return
        
        self._running = True
        self._thread = threading.Thread(target=self._training_loop, args=(predict_agent, symbol), daemon=True)
        self._thread.start()
        log.info(f"ğŸ”„ Prophet è‡ªåŠ¨è®­ç»ƒå™¨å·²å¯åŠ¨ | é—´éš”: {self.interval_hours}h | æ•°æ®: {self.training_days}å¤©")
    
    def stop(self):
        """åœæ­¢è‡ªåŠ¨è®­ç»ƒ"""
        self._running = False
        log.info("ğŸ›‘ Prophet è‡ªåŠ¨è®­ç»ƒå™¨å·²åœæ­¢")
    
    def _training_loop(
        self,
        predict_agent: PredictAgent,
        symbol: str):
        """è®­ç»ƒå¾ªç¯"""
        import time
        
        interval_seconds = self.interval_hours * 3600
        
        while self._running:
            try:
                # æ‰§è¡Œè®­ç»ƒ
                self._do_train(predict_agent, symbol)
                self.train_count += 1
                self.last_train_time = datetime.now()
                
                # ç­‰å¾…ä¸‹ä¸€æ¬¡è®­ç»ƒ
                log.info(f"â³ ä¸‹æ¬¡è‡ªåŠ¨è®­ç»ƒ: {self.interval_hours}h å")
                
                # åˆ†æ®µç¡çœ ä»¥ä¾¿åŠæ—¶å“åº”åœæ­¢ä¿¡å·
                for _ in range(int(interval_seconds)):
                    if not self._running:
                        break
                    time.sleep(1)
                    
            except Exception as e:
                log.error(f"âŒ è‡ªåŠ¨è®­ç»ƒå¤±è´¥: {e}")
                # å‡ºé”™åç­‰å¾… 10 åˆ†é’Ÿå†é‡è¯•
                time.sleep(600)
    
    def _do_train(
        self,
        predict_agent: PredictAgent,
        symbol: str
    ):
        """æ‰§è¡Œè®­ç»ƒ"""
        log.info(f"ğŸ”® å¼€å§‹è‡ªåŠ¨è®­ç»ƒ Prophet ML æ¨¡å‹...")
        
        model_path = f'models/prophet_lgb_{symbol}.pkl'
        
        # 1. è·å–å†å²æ•°æ®
        df = self._fetch_data(symbol)
        if df is None or len(df) < 500:
            log.warning(f"æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è®­ç»ƒ (å½“å‰: {len(df) if df is not None else 0})")
            return
        
        # 2. è®¡ç®—æŒ‡æ ‡
        from src.data.processor import MarketDataProcessor
        processor = MarketDataProcessor()
        df_with_indicators = processor._calculate_indicators(df.copy())
        
        # 3. æ„å»ºç‰¹å¾
        from src.features.technical_features import TechnicalFeatureEngineer
        feature_engineer = TechnicalFeatureEngineer()
        features_df = feature_engineer.build_features(df_with_indicators)
        
        # 4. ç”Ÿæˆæ ‡ç­¾
        label_generator = LabelGenerator(horizon_minutes=30, up_threshold=0.001)
        numeric_features = features_df.select_dtypes(include=[np.number])
        X, y = label_generator.prepare_training_data(numeric_features, df, 'close')
        
        if len(X) < 100:
            log.warning(f"æœ‰æ•ˆæ ·æœ¬ä¸è¶³ï¼Œè·³è¿‡è®­ç»ƒ (å½“å‰: {len(X)})")
            return
        
        # 5. åˆ†å‰²æ•°æ®
        split_idx = int(len(X) * 0.8)
        X_train, X_val = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_val = y.iloc[:split_idx], y.iloc[split_idx:]
        
        # 6. è®­ç»ƒæ¨¡å‹
        model = ProphetMLModel()
        metrics = model.train(X_train, y_train, X_val, y_val)
        
        # 7. ä¿å­˜æ¨¡å‹
        model.save(model_path)
        
        # 8. é‡æ–°åŠ è½½åˆ° PredictAgent
        predict_agent.load_ml_model(model_path)
        
        log.info(f"âœ… è‡ªåŠ¨è®­ç»ƒå®Œæˆ! è®­ç»ƒæ¬¡æ•°: #{self.train_count + 1}")
        log.info(f"   è®­ç»ƒ AUC: {metrics.get('train_auc', 0):.4f}")
        log.info(f"   éªŒè¯ AUC: {metrics.get('val_auc', 0):.4f}")
    
    def _fetch_data(
        self,
        symbol: str
    ) -> pd.DataFrame:
        """è·å–å†å²æ•°æ®"""
        try:
            limit = self.training_days * 24 * 12  # 5åˆ†é’ŸKçº¿
            
            all_klines = []
            remaining = limit
            end_time = None
            
            while remaining > 0:
                batch_size = min(remaining, 1000)
                klines = self.client.client.futures_klines(
                    symbol=symbol,
                    interval='5m',
                    limit=batch_size,
                    endTime=end_time
                )
                
                if not klines:
                    break
                
                all_klines = klines + all_klines
                end_time = klines[0][0] - 1
                remaining -= batch_size
            
            # è½¬æ¢ä¸º DataFrame
            df = pd.DataFrame(all_klines, columns=[
                'timestamp', 'open', 'high', 'low', 'close', 'volume',
                'close_time', 'quote_volume', 'trades', 'taker_buy_base',
                'taker_buy_quote', 'ignore'
            ])
            
            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
            for col in ['open', 'high', 'low', 'close', 'volume']:
                df[col] = df[col].astype(float)
            
            df.set_index('timestamp', inplace=True)
            df = df.sort_index()
            
            log.info(f"ğŸ“¥ è·å– {len(df)} æ¡å†å² K çº¿")
            return df
            
        except Exception as e:
            log.error(f"è·å–å†å²æ•°æ®å¤±è´¥: {e}")
            return None


# å¯¼å‡º
__all__ = ['ProphetMLModel', 'LabelGenerator', 'ProphetAutoTrainer', 'HAS_LIGHTGBM']
